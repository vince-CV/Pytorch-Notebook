{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Inference on Production</font>\n",
    "\n",
    "Imagine a situation; you and your team are working on a project that has a few ML problems to be solved. You picked one problem and solved using the PyTorch framework. However, your colleague used Tensorflow to solve the other problem. Both problems are a part of a bigger project. In this scenario, it is obvious to wish for a common format to share ML models.\n",
    "\n",
    "ONNX ([Open Neural Network Exchange](https://onnx.ai/)) is one such open format that allows us to model interchange between various [ML frameworks and tools](https://onnx.ai/supported-tools).\n",
    "\n",
    "\n",
    "**In this notebook, we will see how to convert a PyTorch Lightning saved checkpoint to the ONNX model.  Let's take an example of the checkpoint saved by the last notebook of MNIST training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">Lightning Module</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNet5(pl.LightningModule):  # here nn.Module is replaced by LightningModule\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Save the arguments as hyperparameters. \n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "            # First convolution Layer\n",
    "            # input size = (32, 32), output size = (28, 28)\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Max pool 2-d\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            # Second convolution layer\n",
    "            # input size = (14, 14), output size = (10, 10)\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # output size = (5, 5)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            # First fully connected layer\n",
    "            # in_features = total number of weights in last conv layer = 16 * 5 * 5\n",
    "            nn.Linear(in_features=16 * 5 * 5, out_features=120), \n",
    "            \n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # second fully connected layer\n",
    "            # in_features = output of last linear layer = 120 \n",
    "            nn.Linear(in_features=120, out_features=84), \n",
    "            \n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Third fully connected layer. It is also output layer\n",
    "            # in_features = output of last linear layer = 84\n",
    "            # and out_features = number of classes = 10 (MNIST data 0-9)\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # apply feature extractor\n",
    "        x = self._body(x)\n",
    "        # flatten the output of conv layers\n",
    "        # dimension should be batch_size * number_of weights_in_last conv_layer\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        # apply classification head\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        # get data and labels from batch\n",
    "        data, target = batch\n",
    "\n",
    "        # get prediction\n",
    "        output = self(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # get probability score using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]\n",
    "        \n",
    "        acc = accuracy(pred=pred, target=target)\n",
    "        \n",
    "        \n",
    "        dic = {\n",
    "            'train_loss': loss,\n",
    "            'train_acc': acc\n",
    "        }\n",
    "        \n",
    "\n",
    "        return {'loss': loss, 'log': dic, 'progress_bar': dic}\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        # training_step_outputs = [{'loss': loss, 'log': dic, 'progress_bar': dic}, ..., \n",
    "        #{'loss': loss, 'log': dic, 'progress_bar': dic}]\n",
    "        avg_train_loss = torch.tensor([x['progress_bar']['train_loss'] for x in training_step_outputs]).mean()\n",
    "        avg_train_acc = torch.tensor([x['progress_bar']['train_acc'] for x in training_step_outputs]).mean()\n",
    "        \n",
    "        \n",
    "        dic = {\n",
    "            'epoch_train_loss': avg_train_loss,\n",
    "            'epoch_train_acc': avg_train_acc\n",
    "        }\n",
    "        return {'log': dic, 'progress_bar': dic}\n",
    "        \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        # get data and labels from batch\n",
    "        data, target = batch\n",
    "        \n",
    "        # get prediction\n",
    "        output = self(data)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # get probability score using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]\n",
    "        \n",
    "        acc = accuracy(pred=pred, target=target)\n",
    "        \n",
    "        dic = {\n",
    "            'v_loss': loss,\n",
    "            'v_acc': acc\n",
    "        }\n",
    "        \n",
    "        return dic\n",
    "    \n",
    "    \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        # validation_step_outputs = [dic, ..., dic]\n",
    "        \n",
    "        avg_val_loss = torch.tensor([x['v_loss'] for x in validation_step_outputs]).mean()\n",
    "        avg_val_acc = torch.tensor([x['v_acc'] for x in validation_step_outputs]).mean()\n",
    "        \n",
    "        \n",
    "        dic = {\n",
    "            'avg_val_loss': avg_val_loss,\n",
    "            'avg_val_acc': avg_val_acc\n",
    "        }\n",
    "        return {'val_loss': avg_val_loss, 'log': dic, 'progress_bar': dic}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=self.hparams.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">Get the Checkpoint</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_latest_run_version_ckpt_epoch_no(lightning_logs_dir='lightning_logs', run_version=None):\n",
    "    if run_version is None:\n",
    "        run_version = 0\n",
    "        for dir_name in os.listdir(lightning_logs_dir):\n",
    "            if 'version' in dir_name:\n",
    "                if int(dir_name.split('_')[1]) > run_version:\n",
    "                    run_version = int(dir_name.split('_')[1])\n",
    "                \n",
    "    checkpoints_dir = os.path.join(lightning_logs_dir, 'version_{}'.format(run_version), 'checkpoints')\n",
    "    \n",
    "    files = os.listdir(checkpoints_dir)\n",
    "    ckpt_filename = None\n",
    "    for file in files:\n",
    "        if file.endswith('.ckpt'):\n",
    "            ckpt_filename = file\n",
    "        \n",
    "    if ckpt_filename is not None:\n",
    "        ckpt_path = os.path.join(checkpoints_dir, ckpt_filename)\n",
    "    else:\n",
    "        print('CKPT file is not present')\n",
    "    \n",
    "    return ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt_path: lightning_logs/version_5/checkpoints/epoch=7.ckpt\n"
     ]
    }
   ],
   "source": [
    "# get checkpoint path\n",
    "ckpt_path = get_latest_run_version_ckpt_epoch_no(run_version=5)\n",
    "print('ckpt_path: {}'.format(ckpt_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">Convert to ONNX Format</font>\n",
    "\n",
    "Get details [here](https://pytorch-lightning.readthedocs.io/en/latest/production_inference.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "def convert_to_onnx_model(model, ckpt_path, onnx_path=None):\n",
    "    \n",
    "    # ONNX filename\n",
    "    if onnx_path is None:\n",
    "        onnx_path = ckpt_path[:-4] + 'onnx'\n",
    "        \n",
    "    # Load the checkpoint\n",
    "    ckpt_model = model.load_from_checkpoint(ckpt_path)\n",
    "    \n",
    "    # Freeze the network\n",
    "    ckpt_model.freeze()\n",
    "    \n",
    "    # Add a sample input. Here input shape = (batch_size, num_channel, height, width)\n",
    "    input_sample = torch.randn((1, 1, 32, 32))\n",
    "    \n",
    "    # convert to ONNX model\n",
    "    ckpt_model.to_onnx(onnx_path, input_sample, export_params=True)\n",
    "    \n",
    "    return onnx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx_model_path: lightning_logs/version_5/checkpoints/epoch=7.onnx\n"
     ]
    }
   ],
   "source": [
    "# initiate the model\n",
    "model = LeNet5()\n",
    "\n",
    "# convert the checkpoint to onnx format\n",
    "onnx_model_path = convert_to_onnx_model(model, ckpt_path)\n",
    "print('onnx_model_path: {}'.format(onnx_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">Sample Inference</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.7201431 ,  0.54916894,  2.4066284 ,  0.9954219 , -1.7776055 ,\n",
      "         0.395705  , -1.6241193 ,  0.5397513 , -0.983725  , -1.1929322 ]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# init a session\n",
    "sess = onnxruntime.InferenceSession(onnx_model_path)\n",
    "\n",
    "# get input name from session\n",
    "input_name = sess.get_inputs()[0].name\n",
    "\n",
    "# prepare inputs\n",
    "inputs = {input_name: np.random.randn(1, 1, 32, 32).astype(np.float32)}\n",
    "\n",
    "# get output\n",
    "outputs = sess.run(None, inputs)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">References</font>\n",
    "\n",
    "\n",
    "1. https://pytorch-lightning.readthedocs.io/en/latest/production_inference.html\n",
    "\n",
    "1. https://docs.microsoft.com/en-us/windows/ai/windows-ml/get-onnx-model\n",
    "\n",
    "1. https://onnx.ai/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
